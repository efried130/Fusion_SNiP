{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd3330f8",
   "metadata": {},
   "source": [
    "# Satellite Spatiotemporal Fusion Approaches to Monitor River Sediment Dynamics - HUC 05 - AQUAFUSION\n",
    "\n",
    "\n",
    "### Elisa Friedmann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9fed121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83816bd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\\\\\Users\\\\\\\\Ellie\\\\\\\\Documents\\\\\\\\UMass\\\\\\\\SNiP\\\\\\\\model_reflSed\\\\\\\\data\\\\\\\\FusionTest_PittsburgSites_ratios_matchups2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#read data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#fusion and aquasat\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m fusionTest5 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mEllie\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUMass\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mSNiP\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mmodel_reflSed\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mFusionTest_PittsburgSites_ratios_matchups2.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m aquaHuc5 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mEllie\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUMass\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSNiP\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmodel_reflSed\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124maquasat_huc5_ratio.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/work/efriedmann_umass_edu/.conda/envs/fusion_SNiP/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/efriedmann_umass_edu/.conda/envs/fusion_SNiP/lib/python3.10/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/efriedmann_umass_edu/.conda/envs/fusion_SNiP/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/work/efriedmann_umass_edu/.conda/envs/fusion_SNiP/lib/python3.10/site-packages/pandas/io/parsers/readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/efriedmann_umass_edu/.conda/envs/fusion_SNiP/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1216\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/work/efriedmann_umass_edu/.conda/envs/fusion_SNiP/lib/python3.10/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\\\\\Users\\\\\\\\Ellie\\\\\\\\Documents\\\\\\\\UMass\\\\\\\\SNiP\\\\\\\\model_reflSed\\\\\\\\data\\\\\\\\FusionTest_PittsburgSites_ratios_matchups2.csv'"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "#fusion and aquasat\n",
    "fusionTest5 = pd.read_csv(r'C:\\\\Users\\\\Ellie\\\\Documents\\\\UMass\\\\SNiP\\\\model_reflSed\\\\data\\\\FusionTest_PittsburgSites_ratios_matchups2.csv')\n",
    "aquaHuc5 = pd.read_csv(r'C:\\\\Users\\\\Ellie\\\\Documents\\\\UMass\\\\SNiP\\\\model_reflSed\\\\data\\\\aquasat_huc5_ratio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d6423",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fusionTest5.columns.values.tolist())\n",
    "print(aquaHuc5.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea2bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#synchronize column names\n",
    "\n",
    "fusionTest5 = fusionTest5.assign(\n",
    "                #red = fusionTest5.ls_red,\n",
    "                #green = fusionTest5.ls_green,\n",
    "                #blue = fusionTest5.ls_blue,\n",
    "                #nir = fusionTest5.ls_nir,\n",
    "                #swir1 = fusionTest5.ls_swir1,\n",
    "                #swir2 = fusionTest5.ls_swir2,\n",
    "                lat = fusionTest5.lat_x,\n",
    "                long = fusionTest5.long_x,\n",
    "                #tss = fusionTest5.value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add band ratios\n",
    "\n",
    "fusionTest5 = fusionTest5.assign(NR = fusionTest5['nir']/fusionTest5['red'],\n",
    "                BR = fusionTest5['blue']/fusionTest5['red'],\n",
    "                GR = fusionTest5['green']/fusionTest5['red'],\n",
    "                SR = fusionTest5['swir1']/fusionTest5['red'],\n",
    "                BG = fusionTest5['blue']/fusionTest5['green'],\n",
    "                RG = fusionTest5['red']/fusionTest5['green'],\n",
    "                NG = fusionTest5['nir']/fusionTest5['green'],\n",
    "                SG = fusionTest5['swir1']/fusionTest5['green'],\n",
    "                BN = fusionTest5['blue']/fusionTest5['nir'],\n",
    "                GN = fusionTest5['green']/fusionTest5['nir'],\n",
    "                RN = fusionTest5['red']/fusionTest5['nir'],\n",
    "                SN = fusionTest5['swir1']/fusionTest5['nir'],\n",
    "                BS = fusionTest5['blue']/fusionTest5['swir1'],\n",
    "                GS = fusionTest5['green']/fusionTest5['swir1'],\n",
    "                RS = fusionTest5['red']/fusionTest5['swir1'],\n",
    "                NS = fusionTest5['nir']/fusionTest5['swir1'],\n",
    "                R_GN = fusionTest5['red']/ (fusionTest5['green'] + fusionTest5['nir']),\n",
    "                R_GB = fusionTest5['red']/ (fusionTest5['green'] + fusionTest5['blue']),\n",
    "                R_GS = fusionTest5['red']/ (fusionTest5['green'] + fusionTest5['swir1']),\n",
    "                R_BN = fusionTest5['red']/ (fusionTest5['blue'] + fusionTest5['nir']),\n",
    "                R_BS = fusionTest5['red']/ (fusionTest5['blue'] + fusionTest5['swir1']),\n",
    "                R_NS = fusionTest5['red']/ (fusionTest5['nir'] + fusionTest5['swir1']),\n",
    "                G_BR = fusionTest5['green']/ (fusionTest5['blue'] + fusionTest5['red']),\n",
    "                G_BN = fusionTest5['green'] / (fusionTest5['blue'] + fusionTest5['nir']),\n",
    "                G_BS = fusionTest5['green'] / (fusionTest5['blue'] + fusionTest5['swir1']),\n",
    "                G_RN = fusionTest5['green'] / (fusionTest5['red'] + fusionTest5['nir']),\n",
    "                G_RB = fusionTest5['green'] / (fusionTest5['red'] + fusionTest5['blue']),\n",
    "                G_NS = fusionTest5['green'] / (fusionTest5['nir'] + fusionTest5['swir1']),\n",
    "                B_RG = fusionTest5['blue'] / (fusionTest5['red'] + fusionTest5['green']),\n",
    "                B_RN = fusionTest5['blue'] / (fusionTest5['red'] + fusionTest5['nir']),\n",
    "                B_RS = fusionTest5['blue'] / (fusionTest5['red'] + fusionTest5['swir1']),\n",
    "                B_GN = fusionTest5['blue'] / (fusionTest5['green'] + fusionTest5['nir']),\n",
    "                B_GS = fusionTest5['blue'] / (fusionTest5['green'] + fusionTest5['swir1']),\n",
    "                B_NS = fusionTest5['blue'] / (fusionTest5['nir'] + fusionTest5['swir1']),\n",
    "                N_RG = fusionTest5['nir'] / (fusionTest5['red'] + fusionTest5['green']),\n",
    "                N_RB = fusionTest5['nir'] / (fusionTest5['red'] + fusionTest5['blue']),\n",
    "                N_RS = fusionTest5['nir'] / (fusionTest5['red'] + fusionTest5['swir1']),\n",
    "                N_GB = fusionTest5['nir'] / (fusionTest5['green'] + fusionTest5['blue']),\n",
    "                N_GS = fusionTest5['nir'] / (fusionTest5['green'] + fusionTest5['swir1']),\n",
    "                N_BS = fusionTest5['nir'] / (fusionTest5['blue']  + fusionTest5['swir1']),\n",
    "                \n",
    "                GR2 = (fusionTest5['green'] + fusionTest5['red']) / 2,\n",
    "                GN2 = (fusionTest5['green'] + fusionTest5['nir']) / 2,\n",
    "                #blooms\n",
    "                BR_G = (fusionTest5['blue'] - fusionTest5['red']) / fusionTest5['green'],\n",
    "                NS_NR = (fusionTest5['nir'] - fusionTest5['swir1']) / (fusionTest5['red'] - fusionTest5['swir1']),\n",
    "                fai = fusionTest5['nir'] - (fusionTest5['red'] + (fusionTest5['swir1']-fusionTest5['red'])*((830-660)/(1650-660))),\n",
    "                # fai = (nir - red) + (red -swir) * (830-660)/(1648-660)\n",
    "                N_S= fusionTest5['nir'] - fusionTest5['swir1'],\n",
    "                N_R = fusionTest5['nir']- fusionTest5['red'],\n",
    "                #\n",
    "                ndvi = ((fusionTest5['nir']-fusionTest5['red'])/(fusionTest5['nir']+fusionTest5['red'])),\n",
    "                ndwi = ((fusionTest5['green']- fusionTest5['swir1'])/(fusionTest5['green'] + fusionTest5['swir1'])),\n",
    "                ndssi = ((fusionTest5['blue'] - fusionTest5['nir'])/ (fusionTest5['blue'] + fusionTest5['nir'])),\n",
    "                gn_gn= ((fusionTest5['green']- fusionTest5['nir'])/ (fusionTest5['green'] + fusionTest5['nir'])),\n",
    "                Matchup = 'Fusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a221643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add band ratios\n",
    "\n",
    "aquaHuc5 = aquaHuc5.assign(NR = aquaHuc5['nir']/aquaHuc5['red'],\n",
    "                BR = aquaHuc5['blue']/aquaHuc5['red'],\n",
    "                GR = aquaHuc5['green']/aquaHuc5['red'],\n",
    "                SR = aquaHuc5['swir1']/aquaHuc5['red'],\n",
    "                BG = aquaHuc5['blue']/aquaHuc5['green'],\n",
    "                RG = aquaHuc5['red']/aquaHuc5['green'],\n",
    "                NG = aquaHuc5['nir']/aquaHuc5['green'],\n",
    "                SG = aquaHuc5['swir1']/aquaHuc5['green'],\n",
    "                BN = aquaHuc5['blue']/aquaHuc5['nir'],\n",
    "                GN = aquaHuc5['green']/aquaHuc5['nir'],\n",
    "                RN = aquaHuc5['red']/aquaHuc5['nir'],\n",
    "                SN = aquaHuc5['swir1']/aquaHuc5['nir'],\n",
    "                BS = aquaHuc5['blue']/aquaHuc5['swir1'],\n",
    "                GS = aquaHuc5['green']/aquaHuc5['swir1'],\n",
    "                RS = aquaHuc5['red']/aquaHuc5['swir1'],\n",
    "                NS = aquaHuc5['nir']/aquaHuc5['swir1'],\n",
    "                R_GN = aquaHuc5['red']/ (aquaHuc5['green'] + aquaHuc5['nir']),\n",
    "                R_GB = aquaHuc5['red']/ (aquaHuc5['green'] + aquaHuc5['blue']),\n",
    "                R_GS = aquaHuc5['red']/ (aquaHuc5['green'] + aquaHuc5['swir1']),\n",
    "                R_BN = aquaHuc5['red']/ (aquaHuc5['blue'] + aquaHuc5['nir']),\n",
    "                R_BS = aquaHuc5['red']/ (aquaHuc5['blue'] + aquaHuc5['swir1']),\n",
    "                R_NS = aquaHuc5['red']/ (aquaHuc5['nir'] + aquaHuc5['swir1']),\n",
    "                G_BR = aquaHuc5['green']/ (aquaHuc5['blue'] + aquaHuc5['red']),\n",
    "                G_BN = aquaHuc5['green'] / (aquaHuc5['blue'] + aquaHuc5['nir']),\n",
    "                G_BS = aquaHuc5['green'] / (aquaHuc5['blue'] + aquaHuc5['swir1']),\n",
    "                G_RN = aquaHuc5['green'] / (aquaHuc5['red'] + aquaHuc5['nir']),\n",
    "                G_RB = aquaHuc5['green'] / (aquaHuc5['red'] + aquaHuc5['blue']),\n",
    "                G_NS = aquaHuc5['green'] / (aquaHuc5['nir'] + aquaHuc5['swir1']),\n",
    "                B_RG = aquaHuc5['blue'] / (aquaHuc5['red'] + aquaHuc5['green']),\n",
    "                B_RN = aquaHuc5['blue'] / (aquaHuc5['red'] + aquaHuc5['nir']),\n",
    "                B_RS = aquaHuc5['blue'] / (aquaHuc5['red'] + aquaHuc5['swir1']),\n",
    "                B_GN = aquaHuc5['blue'] / (aquaHuc5['green'] + aquaHuc5['nir']),\n",
    "                B_GS = aquaHuc5['blue'] / (aquaHuc5['green'] + aquaHuc5['swir1']),\n",
    "                B_NS = aquaHuc5['blue'] / (aquaHuc5['nir'] + aquaHuc5['swir1']),\n",
    "                N_RG = aquaHuc5['nir'] / (aquaHuc5['red'] + aquaHuc5['green']),\n",
    "                N_RB = aquaHuc5['nir'] / (aquaHuc5['red'] + aquaHuc5['blue']),\n",
    "                N_RS = aquaHuc5['nir'] / (aquaHuc5['red'] + aquaHuc5['swir1']),\n",
    "                N_GB = aquaHuc5['nir'] / (aquaHuc5['green'] + aquaHuc5['blue']),\n",
    "                N_GS = aquaHuc5['nir'] / (aquaHuc5['green'] + aquaHuc5['swir1']),\n",
    "                N_BS = aquaHuc5['nir'] / (aquaHuc5['blue']  + aquaHuc5['swir1']),\n",
    "                \n",
    "                GR2 = (aquaHuc5['green'] + aquaHuc5['red']) / 2,\n",
    "                GN2 = (aquaHuc5['green'] + aquaHuc5['nir']) / 2,\n",
    "                #blooms\n",
    "                BR_G = (aquaHuc5['blue'] - aquaHuc5['red']) / aquaHuc5['green'],\n",
    "                NS_NR = (aquaHuc5['nir'] - aquaHuc5['swir1']) / (aquaHuc5['red'] - aquaHuc5['swir1']),\n",
    "                fai = aquaHuc5['nir'] - (aquaHuc5['red'] + (aquaHuc5['swir1']-aquaHuc5['red'])*((830-660)/(1650-660))),\n",
    "                # fai = (nir - red) + (red -swir) * (830-660)/(1648-660)\n",
    "                N_S= aquaHuc5['nir'] - aquaHuc5['swir1'],\n",
    "                N_R = aquaHuc5['nir']- aquaHuc5['red'],\n",
    "                #\n",
    "                ndvi = ((aquaHuc5['nir']-aquaHuc5['red'])/(aquaHuc5['nir']+aquaHuc5['red'])),\n",
    "                ndwi = ((aquaHuc5['green']- aquaHuc5['swir1'])/(aquaHuc5['green'] + aquaHuc5['swir1'])),\n",
    "                ndssi = ((aquaHuc5['blue'] - aquaHuc5['nir'])/ (aquaHuc5['blue'] + aquaHuc5['nir'])),\n",
    "                gn_gn= ((aquaHuc5['green']- aquaHuc5['nir'])/ (aquaHuc5['green'] + aquaHuc5['nir'])),\n",
    "                Matchup = 'Aquasat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fdfecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fusionTest5.columns.values.tolist())\n",
    "print(aquaHuc5.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8623b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select appropriate rows and columns for model\n",
    "fusionTest5 = fusionTest5[['SiteID', 'date', 'NR', 'BR', 'GR', 'SR', 'BG', \\\n",
    "                           'RG', 'NG', 'SG', 'BN', 'GN', 'RN', 'SN', 'BS', 'GS', 'RS', 'NS', 'R_GN', 'R_GB', 'R_GS', \\\n",
    "                           'R_BN', 'R_BS', 'R_NS', 'G_BR', 'G_BN', 'G_BS', 'G_RN', 'G_RB', 'G_NS', 'B_RG', 'B_RN', 'B_RS', \\\n",
    "                           'B_GN', 'B_GS', 'B_NS', 'N_RG', 'N_RB', 'N_RS', 'N_GB', 'N_GS', 'N_BS', 'GR2', 'GN2', 'BR_G', \\\n",
    "                           'NS_NR', 'fai', 'N_S', 'N_R', 'ndvi', 'ndwi', 'ndssi', 'gn_gn', 'hydroCondition', 'hydroEvent',\\\n",
    "                           'red', 'green', 'blue', 'nir', 'swir1','swir2', 'lat', 'long', 'tss', 'Matchup']]\n",
    "\n",
    "aquaHuc5 = aquaHuc5[['SiteID', 'lat', 'long', 'date', 'hydroCondition', 'hydroEvent', 'blue', \\\n",
    "                     'green', 'nir', 'red', 'swir1', 'swir2', 'tss', 'NR', 'BR', 'GR', \\\n",
    "                     'SR', 'BG', 'RG', 'NG', 'SG', 'BN', 'GN', 'RN', 'SN', 'BS', 'GS', 'RS', 'NS', 'GR2', 'GN2', \\\n",
    "                     'BR_G', 'NS_NR', 'fai', 'N_S', 'N_R', 'ndvi', 'ndwi', 'ndssi', 'R_GN', 'R_GB', 'R_GS', \\\n",
    "                     'R_BN', 'R_BS', 'R_NS', 'G_BR', 'G_BN', 'G_BS', 'G_RN', 'G_RB', 'G_NS', 'B_RG', 'B_RN', 'B_RS', \\\n",
    "                     'B_GN', 'B_GS', 'B_NS', 'N_RG', 'N_RB', 'N_RS', 'N_GB', 'N_GS', 'N_BS', 'gn_gn', 'Matchup']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5fbbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Plot\n",
    "aquaHuc5 = aquaHuc5[(aquaHuc5.red > 0) & (aquaHuc5.nir > 0) & (aquaHuc5.blue > 0) & (aquaHuc5.green > 0) & (aquaHuc5.swir1 > 0) & (aquaHuc5.swir2 > 0)]\n",
    "import plotly.express as px\n",
    "scatter = px.scatter(aquaHuc5, x=aquaHuc5['R_GB'], y=aquaHuc5[\"tss\"])\n",
    "scatter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge dataframes\n",
    "aquaFusion_huc5_Test = pd.concat([fusionTest5, aquaHuc5], axis = 0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f0ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb39d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aquaFusion_huc5_Test.SiteID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adbf219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for fusion sites\n",
    "sites = ['USGS-03049625','USGS-03086000','21PA_WQX-WQN0801','21PA_WQX-WQN0701','21PA_WQX-WQN0902','21PA_WQX-WQN0905']\n",
    "\n",
    "aquaFusion = aquaFusion_huc5_Test[aquaFusion_huc5_Test['SiteID'].isin(sites)]\n",
    "aquaFusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d9ae2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692cde03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aquaFusion = pd.read_csv(\"C:\\\\Users\\\\Ellie\\\\Documents\\\\UMass\\\\SNiP\\\\RS_Fusion\\\\aquaFusion_17_32_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca388d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Plot\n",
    "#aquaFusion = aquaFusion[(aquaFusion.red > 0) & (aquaFusion.nir > 0) & (aquaFusion.blue > 0) & (aquaFusion.green > 0) & (aquaFusion.swir1 > 0) & (aquaFusion.swir2 > 0)]\n",
    "\n",
    "import plotly.express as px\n",
    "scatter = px.scatter(aquaFusion, x=aquaFusion['Date'], y=aquaFusion[\"tss\"], template='simple_white', facet_col=\"Site\",\n",
    "                     color = 'Matchup', facet_col_wrap=2,\n",
    "                     title = 'Timeseries of Fusion and Aquasat TSS-Reflectance Matchups', \n",
    "                     labels={\n",
    "                     \"tss\": \"TSS [mg/L])\",\n",
    "                     \"Date\": \"Date\"})\n",
    "\n",
    "# #scatter.add_annotation(text=\"Fusion R squared = 0.37\",\n",
    "#                   xref=\"paper\", yref=\"paper\",\n",
    "#                   x=0.02, y=1.0, showarrow=False)\n",
    "\n",
    "# #scatter.add_annotation(text=\"Aquasat R squared = 0.43\",\n",
    "#                   xref=\"paper\", yref=\"paper\",\n",
    "#                   x=0.02, y=0.9, showarrow=False)\n",
    "\n",
    "\n",
    "scatter.update_layout(\n",
    "    font=dict(\n",
    "        size=14\n",
    "    )\n",
    ")\n",
    "scatter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd495634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aquaFusion.to_csv(\"C:\\\\Users\\\\Ellie\\\\Documents\\\\UMass\\\\SNiP\\\\RS_Fusion\\\\aquaFusion_17_32.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e375d13b",
   "metadata": {},
   "source": [
    "# Random Forest Model Exploration to learn sediment concentration from reflectance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39457da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean, arange\n",
    "from numpy import std\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import RepeatedKFold, RepeatedStratifiedKFold\n",
    "from sklearn import ensemble, datasets, tree\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import OrderedDict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a899b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select columns of interest\n",
    "df= aquaFusion[['blue', 'green', 'nir', 'red', 'swir1', 'swir2', 'tss', 'NR', 'BR', 'GR', \\\n",
    "                     'SR', 'BG', 'RG', 'NG', 'SG', 'BN', 'GN', 'RN', 'SN', 'BS', 'GS', 'RS', 'NS', 'GR2', 'GN2', \\\n",
    "                     'BR_G', 'NS_NR', 'fai', 'N_S', 'N_R', 'ndvi', 'ndwi', 'ndssi', 'R_GN', 'R_GB', 'R_GS', \\\n",
    "                     'R_BN', 'R_BS', 'R_NS', 'G_BR', 'G_BN', 'G_BS', 'G_RN', 'G_RB', 'G_NS', 'B_RG', 'B_RN', 'B_RS', \\\n",
    "                     'B_GN', 'B_GS', 'B_NS', 'N_RG', 'N_RB', 'N_RS', 'N_GB', 'N_GS', 'N_BS', 'gn_gn']]\n",
    "\n",
    "#Add transformations if needed\n",
    "#natural log\n",
    "# df['R_GB_log'] = np.log(df['R_GB'])\n",
    "# df['R_GS_log'] = np.log(df['R_GS'])\n",
    "# df['BS_log'] = np.log(df['BS'])\n",
    "# df['B_GS_log'] = np.log(df['B_GS'])\n",
    "# df['BR_G_log'] = np.log(df['BR_G'])\n",
    "\n",
    "\n",
    "df = df[(df.red > 0) & (df.nir > 0) & (df.blue > 0) & (df.green > 0) & (df.swir1 > 0) & (df.swir2 > 0)]\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6435ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Training and Testing Set\n",
    "\n",
    "# Arrange Data into Features Matrix and Target Vector\n",
    "X = df.loc[:, df.columns != 'tss']\n",
    "y = df.loc[:, 'tss'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "# summarize the dataset\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Plot\n",
    "import plotly.express as px\n",
    "scatter = px.scatter(df, x=df['R_GS'], y=df[\"tss\"])\n",
    "scatter.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b656464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "model = RandomForestRegressor(bootstrap = True, oob_score= True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a246308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest 1: No fit\n",
    "\n",
    "#Quick eval raw\n",
    "model.fit(X_train, y_train)\n",
    "print('Trained model oob score', model.oob_score_)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "#Metrics for Model 1 \n",
    "\n",
    "RMSE_model = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "\n",
    "#Metrics\n",
    "print('Training score', model.score(X_train, y_train))\n",
    "print('RMSE', RMSE_model)\n",
    "print('Testing score', model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metric Plots\n",
    "\n",
    "#Feature importance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "#\n",
    "# Get Feature importance data using feature_importances_ attribute\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "feature_importance = model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.ylabel('Band')\n",
    "plt.xlabel('Importance (%)')\n",
    "plt.yticks(pos, np.array(X.columns)[sorted_idx], size = 12)\n",
    "plt.title('Feature Importance')\n",
    "result = permutation_importance(model, X_test, y_test, n_repeats=10,\n",
    "                                random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Actual vs Predicted plot\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(y_test, prediction, c='crimson')\n",
    "\n",
    "p1 = max(max(prediction), max(y_test))\n",
    "p2 = min(min(prediction), min(y_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.xlabel('True Values', fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing the Random Forest through a grid search with CV\n",
    "\n",
    "## I will optimize:\n",
    "\n",
    "#max_features\n",
    "#n_estimators\n",
    "#max_depth\n",
    "\n",
    "\n",
    "###DO not run as it takes a lot of time. See results below.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = RandomForestRegressor(bootstrap = True, oob_score= True, random_state = 42, verbose = 1)\n",
    "param_grid = {\n",
    "            \"n_estimators\" : [100, 150, 200, 300],\n",
    "            \"max_features\" : [\"auto\", \"log2\", \"sqrt\"],\n",
    "            \"max_depth\"    : [1, 4, 8, 10, 12]\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=estimator, param_grid=param_grid, cv= 5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "forest = grid.best_estimator_\n",
    "\n",
    "grid_prediction=forest.predict(X_test)\n",
    "\n",
    "print ('Grid best score:', grid.best_score_, 'Grid best params:', grid.best_params_)\n",
    "\n",
    "mae_grid = mean_absolute_error(y_test, grid_prediction)\n",
    "RMSE_model_grid = np.sqrt(mean_squared_error(y_test, grid_prediction))\n",
    "\n",
    "print('MAE:', mae_grid)\n",
    "print('RMSE:', RMSE_model_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0a8d3e",
   "metadata": {},
   "source": [
    "Grid best score: 0.7204301629272072 Grid best params: {'max_depth': 10, 'max_features': 'log2', 'n_estimators': 150}\n",
    "MAE: 0.323724944699268\n",
    "RMSE: 0.5263227339501133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398992f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_depth\n",
    "# Setup evaluation with 10-fold cv\n",
    "k_fold = 10\n",
    "dep = np.arange(0,0.1,100)\n",
    "\n",
    "scores = []\n",
    "for i in dep:\n",
    "    cv = cross_val_score(RandomForestRegressor(random_state=42,max_depth=5, ccp_alpha =i), X_train, y_train, cv=k_fold, scoring='neg_mean_squared_error').mean()\n",
    "    scores.append(cv)\n",
    "    print(f'Processed Regression Tree (depth={i})')\n",
    "best = dep[np.argmin(np.array(scores)*-1)]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(dep, np.array(scores)*-1, '-o')\n",
    "plt.axvline(best, color = 'r', ls=\"--\")\n",
    "plt.xlabel('ccp_alpha',fontsize=14)\n",
    "plt.ylabel('Mean Square Error',fontsize=14)\n",
    "plt.title(f'k-fold cross validation (k={k_fold})',fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c712cb2",
   "metadata": {},
   "source": [
    "## Test optimized model and transformed best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9afa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "model1 = RandomForestRegressor(max_depth = 12, n_estimators = 150, min_samples_split = 2, max_features = 'log2', bootstrap = True, oob_score= True, warm_start = False, ccp_alpha = 0, min_impurity_decrease = 0)\n",
    "\n",
    "\n",
    "\n",
    "#Quick eval raw\n",
    "model1.fit(X_train, y_train)\n",
    "print('Trained model oob score', 1 - model1.oob_score_)\n",
    "\n",
    "prediction1 = model1.predict(X_test)\n",
    "print('Test Score', model1.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c944ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Error: Model 1 RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#TEST\n",
    "\n",
    "RMSE_model1 = np.sqrt(mean_squared_error(y_test, prediction1))\n",
    "\n",
    "#Metrics\n",
    "print('Training score', model1.score(X_train, y_train))\n",
    "print('RMSE', RMSE_model1)\n",
    "print('Testing score', model1.score(X_test, y_test))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_test, prediction1, c='crimson')\n",
    "\n",
    "p1 = max(max(prediction1), max(y_test))\n",
    "p2 = min(min(prediction1), min(y_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.xlabel('Actual', fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "#\n",
    "# Get Feature importance data using feature_importances_ attribute\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "feature_importance = model1.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.ylabel('Band')\n",
    "plt.xlabel('Importance (%)')\n",
    "plt.yticks(pos, np.array(X.columns)[sorted_idx], size = 15)\n",
    "plt.title('Feature Importance')\n",
    "result = permutation_importance(model1, X_test, y_test, n_repeats=10,\n",
    "                                random_state=42, n_jobs=2)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8eedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect the test set predictions for d-h models\n",
    "\n",
    "model_pred = model.predict(X_test)\n",
    "model1_pred = model1.predict(X_test)\n",
    "\n",
    "\n",
    "# Keep predictions of models d-h\n",
    "model_train_pred = [model.predict(X_train),model1.predict(X_train)]\n",
    "\n",
    "model_test_pred = [model.predict(X_test),model1.predict(X_test)]\n",
    "\n",
    "# predicted MAE and MSE for training data\n",
    "\n",
    "models_MAE = []\n",
    "for i in model_train_pred:\n",
    "    MAE = np.round(mean_absolute_error(y_train, i),2)\n",
    "    models_MAE.append(MAE)\n",
    "\n",
    "models_RMSE = []\n",
    "for i in model_train_pred:\n",
    "    RMSE = np.round(np.sqrt(mean_squared_error(y_train, i)),2)\n",
    "    models_RMSE.append(RMSE)\n",
    "\n",
    "    \n",
    "# Plot\n",
    "mod_names=['RF1', 'RF2']\n",
    "metric=pd.DataFrame(['MAE','RMSE'],columns=['Metric'])\n",
    "df = pd.concat([metric,pd.DataFrame([models_MAE,models_RMSE],columns=mod_names)],axis=1)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "ax = df.plot(x=\"Metric\", y=mod_names, kind=\"bar\", title = 'Training Metrics', figsize=(10,8))\n",
    "# annotate\n",
    "ax.bar_label(ax.containers[0], label_type='edge')\n",
    "ax.bar_label(ax.containers[1], label_type='edge')\n",
    "# pad the spacing between the number and the edge of the figure\n",
    "ax.margins(y=0.1)\n",
    "plt.ylabel('Training Metric Score (mg/L)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict MAE and RMSE for test data\n",
    "\n",
    "models_MAE_test = []\n",
    "for i in model_test_pred:\n",
    "    MAE = np.round(mean_absolute_error(y_test, i),2)\n",
    "    models_MAE_test.append(MAE)\n",
    "\n",
    "models_RMSE_test = []\n",
    "for i in model_test_pred:\n",
    "    RMSE = np.round(np.sqrt(mean_squared_error(y_test, i)),2)\n",
    "    models_RMSE_test.append(RMSE)\n",
    "\n",
    "# Plot\n",
    "df = pd.concat([metric,pd.DataFrame([models_MAE_test,models_RMSE_test],columns=mod_names)],axis=1)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "ax = df.plot(x=\"Metric\", y=mod_names, kind=\"bar\", title = 'Testing Metrics', figsize=(10,8))\n",
    "# annotate\n",
    "ax.bar_label(ax.containers[0], label_type='edge')\n",
    "ax.bar_label(ax.containers[1], label_type='edge')\n",
    "# pad the spacing between the number and the edge of the figure\n",
    "ax.margins(y=0.1)\n",
    "plt.ylabel('Test Metric Score (mg/L)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17177ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the tree\n",
    "# fn=X.columns\n",
    "# cn= 'tss'\n",
    "# fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (8,8), dpi=800)\n",
    "# tree.plot_tree(model1.estimators_[0],\n",
    "#                feature_names = fn, \n",
    "#                class_names=cn,\n",
    "#                filled = True);\n",
    "# fig.savefig('rf_individualtree.png')\n",
    "\n",
    "#Visualize multiple trees\n",
    "# This may not the best way to view each estimator as it is small\n",
    "# fn=data.feature_names\n",
    "# cn=data.target_names\n",
    "# fig, axes = plt.subplots(nrows = 1,ncols = 5,figsize = (10,2), dpi=900)\n",
    "# for index in range(0, 5):\n",
    "#     tree.plot_tree(rf.estimators_[index],\n",
    "#                    feature_names = fn, \n",
    "#                    class_names=cn,\n",
    "#                    filled = True,\n",
    "#                    ax = axes[index]);\n",
    "\n",
    "#     axes[index].set_title('Estimator: ' + str(index), fontsize = 11)\n",
    "# fig.savefig('rf_5trees.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352aa3a7",
   "metadata": {},
   "source": [
    "# Run RF only on Sites with both Fusion and Aquasat Site Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef16f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add transformations if needed\n",
    "#natural log\n",
    "df['R_GB_log'] = np.log(df['R_GB'])\n",
    "df['R_GS_log'] = np.log(df['R_GS'])\n",
    "df['BS_log'] = np.log(df['BS'])\n",
    "df['B_GS_log'] = np.log(df['B_GS'])\n",
    "df['BR_G_log'] = np.log(df['BR_G'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84d709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96997da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa15fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5accfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e12fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-fusion_SNiP)",
   "language": "python",
   "name": "conda-env-.conda-fusion_SNiP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
